---
title: "Fundamentals of Missing Data in Evaluation"
subtitle: "Presentation to MSU Department of Psychology, Program Evaluation
           Occasional Speaker Series, East Lansing, MI"
author: 
  - name: Steven J. Pierce
    orcid: 0000-0002-0679-3019
    email: pierces1@msu.edu
institute: "Center for Statistical Training and Consulting"
date: December 5, 2024
title-slide-attributes: 
  data-notes: "1 hr (45-50 min talk + 10-15 min Q & A) My talk today focuses on 
  some concepts and issues related to missing data in program evaluation 
  contexts. My expertise lies in applied statistics, so I'll focus on aspects of 
  missing data relevant to quantitative methods and statistical analyses. Even 
  still, missing data is a big topic and this is just a short talk, so my goal 
  is to teach some fundamental ideas, share some insights and practical advice, 
  then offer resources you can use to learn more on your own. Jot down either my 
  email address or the link you see at the bottom of the screen. My slides, 
  complete with speaker notes, reference list, and links to resources, will be 
  available from that link."
csl: apa-numeric-superscript-brackets.csl
bibliography: references.bib
format: 
  revealjs:
    embed-resources: true
    theme: [default, CSTAT_theme.scss]
    controls: true
    slide-number: c/t
    show-notes: false
    header-logo: graphics/Combomark-Horiz_Green-RGB.png
    footer: <a href="https://github.com/sjpierce/FMDE2024">https://github.com/sjpierce/FMDE2024</a>
    logo: graphics/CSTAT_5x5_Transparent.png
    link-external-icon: true
    link-external-newwindow: true
filters:
  - reveal-header
---

```{r}
#| label: load-packages
#| include: false

library(tidyverse)
library(knitr)
library(kableExtra) # Functions for formatting nice tables. 
```

## Outline
* What is missing data? 
* Why do we end up with missing data? 
* What are the problems with missing data? 
* Why do we care? 
    * Ethics
    * Consequences    
* What should we do about it?
    * Diagnosis
    * Treatment
    * Prevention
* Advice

# What is missing data?
Missing data (MD) are measurements you intended to collect but did not get. 

::: {.incremental}
* Having MD is *common* in research & evaluation studies.
* If you do much evaluation work, you *will* run into MD.
:::

::: {.notes}
In the simplest terms, missing data are simply measurements that you intended to 
collect but did not get. While you can sometimes categorize what kind of missing 
data you have or why it is missing, the basic problem is that you didn't get all 
the data you need. **>** Having missing data is a common issue afflicting 
research and evaluation studies. Entirely avoiding it is difficult and rare. 
**>** If you do much evaluation work, you *will* eventually run into some 
missing data issues. Therefore, it is worth learning about the issue and how to 
handle it.
:::

# Why do we end up with missing data? 
Data collection doesn't always go according to plan...
<br> <br> 

::: {.fragment}
```{r}
#| label: tbl-factors

data.frame(Human = c("Participant behavior", "Evaluator errors", 
                     "Partner behavior"),
           Other = c("Equipment failures", "Records/Databases", 
                     "Unusual Events")) %>%  
  kable(., format = "html", 
        col.names = c("Human Factors", "Other Factors")) %>% 
  kable_classic(full_width = FALSE, lightable_options = c("hover"), 
                html_font = "Lato")
```
:::

::: {.notes}
Like many things in life, data collection doesn't always go according to plan.
Human factors often contribute to the occurrence of missing data. For example, 
a survey participant may skip a question without recording any response, offer 
an illegible or irrelevant answer, refuse to answer it, or simply say 
"I don't know". They may skip whole instruments or entire data collection 
visits. But evaluators occasionally make errors that lead to missing data. 
Imagine forgetting to take a data collection form with you, or programming the 
skip pattern for an online survey incorrectly. Sometimes, our evaluation 
partners' decisions or behavior can prevent obtaining some data we wanted. 
Perhaps they object to sharing something with you, or were not diligent about 
logging some events of interest. 

Other things can go wrong too. Perhaps a physical instrument breaks, or its
battery dies, or your online survey app crashes. If you're using an
organization's records or databases, those may be incomplete, difficult to
search for relevant data, coded in unhelpful ways, or could have been lost or
damaged or even destroyed according to some retention policy. In terms of
events, consider the recent hurricanes in Florida that disrupted data collection
for one of my projects.
:::


# Why should we care about missing data? 

## Ethics: Guiding Principles for Evaluators
Handling missing data well enacts our guiding principles [@AEA-RN8648]: 

:::: {.columns}

::: {.column width="25%"}
![](graphics/AEA_Logo.png){fig-alt="AEA logo." width=150% height=150%}
:::

::: {.column width="75%"}

::: {.incremental}
* Systematic inquiry
* Competence 
* Integrity 
:::

:::

::::

::: {.notes}
Thoughtful handling of missing data is a good way to enact several of AEA's 
guiding principles for evaluators. 

* **>** *Systematic inquiry* demands that we examine the quality of the 
  available data and use it appropriately. We have an obligation to use sound 
  methodology. There are scientific consequences of missing data but there are 
  also legitimate, evidence-based methods for minimizing its impact on our 
  analyses, conclusions, and products. 
* **>** Because poorly handling missing data may compromise our evaluations, 
  *competence* demands that we invest in the skills necessary to understand 
  and handle missing data properly.
* **>** *Integrity* demands that we be transparent about the amount of missing 
  data, how we handled it, and how it may affect our evaluation results.
:::

## Types of Missingness

* Item-level 
* Construct 
* Person-period 
* Planned vs unplanned

## Mechanisms of Missingness

* Missing completely at random (MCAR)
* Missing at random (MAR)
* Missing not at random (MNAR)

## MCAR
MCAR is when neither observed nor unobserved variables predict which data is missing

## MAR

## MNAR

# Consequences
What are the consequences of missing data? 

## Bias
In appropriate handling of missing data can cause analyses to yield biased 
results. 

## Generalizability
Misalignment of analyzed sample and intended population

## Power
Most statistical software defaults to listwise deletion of cases that have any 
missing values on the variables involved in an analysis. That reduces statistical


[@Fernández-García-RN4151; @McKnight-RN1296]

# Diagnosis

## Describing the Amount of MD

[@McKnight-RN1296]

* Numbers & percentages of complete & incomplete cases 
* Number and percentage of missing values for each variable
* Nature and frequency of missing data patterns

## Predictors of Attrition & Missingness in Longitudinal Studies

* Study arm: Compare retention rates 
* Study site (in multisite studies)
* Baseline/pretest values of outcome variables may predict who drops out or has 
  missing values
* Other covariates (demographics, site, )

# Treatment

# Prevention

An ounce of prevention is better than a pound of cure

@de-Leeuw-RN8682, @Wisniewski-RN2978

# Advice

* Collaborate with a statistician! 

## Practical Options

* Item-level missingness in scale scores [@Graham-RN1615; @Newman-RN8223]


## References {.scrollable}

::: {#refs}
:::

